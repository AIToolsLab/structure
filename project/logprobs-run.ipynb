{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a file explaning how the logprobs are calculated"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume we have outline points and sentences for rendering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "outline_sents = [\n",
    "    \"Introduction.\",\n",
    "    \"Goal-oriented.\",\n",
    "    \"Problem solver.\",\n",
    "    \"Leader.\",\n",
    "    \"Values relationships.\"\n",
    "    ]\n",
    "\n",
    "text_sents = [\n",
    "    \"Let me introduce you to Jack.\",\n",
    "    \"He's a driven and ambitious individual with a laser-focused mindset on achieving his goals.\",\n",
    "    \"With a keen eye for detail, he excels in problem-solving and is always seeking new challenges to test his abilities.\",\n",
    "    \"Jack is a natural leader, with the ability to inspire and motivate others to perform at their best.\",\n",
    "    \"Despite his demanding schedule, he always makes time for his family and friends, valuing the importance of maintaining strong relationships.\"\n",
    "    ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTIONS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- EMBEDDINGS --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory(\"./joblib_cache\", verbose = 0)\n",
    "@memory.cache\n",
    "def get_distances_from_query_list(query_list, texts):\n",
    "    list_emb = [get_embedding(text) for text in texts]\n",
    "    distances = []\n",
    "    for query in query_list:\n",
    "        query_emb = get_embedding(query)\n",
    "        distances.append(distances_from_embeddings(query_emb, list_emb))\n",
    "    return distances"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting embeddings is fairly simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.2264650657138757,\n",
       "  0.36996475160295084,\n",
       "  0.3575646639671879,\n",
       "  0.35246010007407635,\n",
       "  0.4129912837999572],\n",
       " [0.27857953635370014,\n",
       "  0.21381096218919704,\n",
       "  0.2724693546505097,\n",
       "  0.28576855853523286,\n",
       "  0.356055233516404],\n",
       " [0.2639245561993384,\n",
       "  0.2760368252369235,\n",
       "  0.23257948277585383,\n",
       "  0.29355789145347466,\n",
       "  0.3503152156442455],\n",
       " [0.27826405756339845,\n",
       "  0.31222124374750504,\n",
       "  0.3298975021518694,\n",
       "  0.2736006624945082,\n",
       "  0.3781515680793055],\n",
       " [0.31181189882958193,\n",
       "  0.33325379115170894,\n",
       "  0.3197764966240627,\n",
       "  0.32030896186849145,\n",
       "  0.2730285304568648]]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outline_raw = '''\n",
    "Introduction.\n",
    "Goal-oriented.\n",
    "Problem solver.\n",
    "Leader.\n",
    "Values relationships.\n",
    "'''\n",
    "text_raw = '''\n",
    "Let me introduce you to Jack.\n",
    "He's a driven and ambitious individual with a laser-focused mindset on achieving his goals.\n",
    "With a keen eye for detail, he excels in problem-solving and is always seeking new challenges to test his abilities.\n",
    "Jack is a natural leader, with the ability to inspire and motivate others to perform at their best.\n",
    "Despite his demanding schedule, he always makes time for his family and friends, valuing the importance of maintaining strong relationships.\n",
    "'''\n",
    "# Tokenizes text into individual words\n",
    "outline_doc = nlp(outline_raw)\n",
    "outline_sections = [sentence.text.strip() for sentence in outline_doc.sents]\n",
    "essay_doc = nlp(text_raw)\n",
    "essay_sections = [sentence.text.strip() for sentence in essay_doc.sents]\n",
    "data = get_distances_from_query_list(outline_sections, essay_sections)\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- LOGPROBS --"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is a helper function that takes a list and an element of interest, and returns a list of possible combinations with an element of interesting being in unique positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_unique_pos(lst, element):\n",
    "    res = []\n",
    "    for i in range(len(lst)):\n",
    "        new_list = lst[:]\n",
    "        new_list.pop(lst.index(element))\n",
    "        res.append(new_list[:i] + [element] + new_list[i:])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 1, 3], [1, 2, 3], [1, 3, 2]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_unique_pos([1,2,3], 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is a helper function that takes a question prompt, and list of sentences of the text, and returns a single string containing the question and text.\n",
    "Format:\n",
    "Question\n",
    "Outline with bullet points in front of each sentence and new line at the end\n",
    "Another new line at the end of the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(outline_sections):\n",
    "    # join the paragraphs into a single string, separated by newlines\n",
    "    essay = '\\n'.join(outline_sections)\n",
    "\n",
    "    # split the essay into a list of sentences\n",
    "    sentences = essay.split('. ')\n",
    "\n",
    "    # join the sentences back into a single string, with each sentence on a new line and\n",
    "    # prepended with a bullet point\n",
    "    outline = 'Write a short essay given this outline:\\n'\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        if sentence:\n",
    "            outline += f'• {sentence.strip()}.'\n",
    "            if i < len(sentences) - 1:\n",
    "                outline += '\\n'\n",
    "\n",
    "    outline += '\\n'  # add a newline character at the end\n",
    "    return outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompt = create_prompt(outline_sents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function concatenates the prompt with the text, to create a full text that will be sent as a request.\n",
    "Returns a single string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_request_template(question_w_outline, sents):\n",
    "    return question_w_outline + ' '.join(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Write a short essay given this outline:\\n• Introduction.\\nGoal-oriented.\\nProblem solver.\\nLeader.\\nValues relationships..\\nLet me introduce you to Jack. He's a driven and ambitious individual with a laser-focused mindset on achieving his goals. With a keen eye for detail, he excels in problem-solving and is always seeking new challenges to test his abilities. Jack is a natural leader, with the ability to inspire and motivate others to perform at their best. Despite his demanding schedule, he always makes time for his family and friends, valuing the importance of maintaining strong relationships.\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_request_query = full_request_template(test_prompt, text_sents)\n",
    "test_request_query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function makes a request to OpenAI to get logprobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def get_response(full_request):\n",
    "  response = openai.Completion.create(\n",
    "      model=\"text-davinci-003\",\n",
    "      prompt = full_request,\n",
    "      temperature=0.7,\n",
    "      max_tokens=256,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0,\n",
    "      logprobs=10,\n",
    "      echo=True\n",
    "    )\n",
    "  return response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a combination list where ONE SENTENCE OF INTEREST is present in all unique places, get the response from openai for that list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_responses(sents, question_w_outline):\n",
    "    response = []\n",
    "    for x in sents:\n",
    "        response.append(get_response(full_request_template(question_w_outline, x)))\n",
    "    return response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is for getting logprobs for every possible combination / order of the sentences.\n",
    "Takes the text sentences, the prompt as input, and returns a list of responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_the_log_probs(sentences, question_w_outline):\n",
    "    res = []\n",
    "    for x in sentences:\n",
    "        res.append(get_all_responses(all_unique_pos(sentences, x), question_w_outline))\n",
    "    return res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is a helper function that calculates the sum of logprobs for the text part.\n",
    "Because we make a request containing the question, spaces and new lines, it takes that fact into account and calculates the sum by counting text offsets.\n",
    "Returns a single number indicating logprobs for the text part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_probs(question_w_outline, original_text, response):\n",
    "    start_point = len(question_w_outline)\n",
    "    start_index = response.choices[0].logprobs.text_offset.index(start_point)\n",
    "    len_original_text = len(original_text)\n",
    "    end_point = start_point + len_original_text - 1\n",
    "    end_index = min(range(len(response.choices[0].logprobs.text_offset)), key=lambda i: abs(response.choices[0].logprobs.text_offset[i] - end_point))\n",
    "    total = 0\n",
    "    for x in range(start_index, end_index + 1):\n",
    "        total = total + response.choices[0].logprobs.token_logprobs[x]\n",
    "    return total"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final function that would calculate all logprobs for all the combinations of the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allLogProbs(res, sentences, question_w_outline):\n",
    "    all_logprobs = []\n",
    "    for i in range(len(sentences)):\n",
    "        combinations = all_unique_pos(sentences, sentences[i])\n",
    "        logprobs = []\n",
    "        for j in range(len(combinations)):\n",
    "            original_text = ' '.join(combinations[j])\n",
    "            logprobs.append(compute_log_probs(question_w_outline, original_text, res[i][j]))\n",
    "        # Get the highest indeces here\n",
    "        # highest_indeces = getHighestIndexes(logprobs, 3)\n",
    "        all_logprobs.append(logprobs)\n",
    "    return all_logprobs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the logprobs, we would need to do the following to get one big result that the front-end could use to render the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-146.409018288316,\n",
       "  -174.6094012188949,\n",
       "  -177.54884178347095,\n",
       "  -184.923083856484,\n",
       "  -171.44304057892901],\n",
       " [-174.6094012188949,\n",
       "  -146.409018288316,\n",
       "  -160.52425362044303,\n",
       "  -164.24308980543395,\n",
       "  -162.279895625332],\n",
       " [-176.6957944925011,\n",
       "  -160.52425362044303,\n",
       "  -146.409018288316,\n",
       "  -157.42897514411194,\n",
       "  -160.48215467138195],\n",
       " [-173.57262323202693,\n",
       "  -159.56882654866195,\n",
       "  -157.42897514411194,\n",
       "  -146.409018288316,\n",
       "  -153.003944198414],\n",
       " [-179.64452757485998,\n",
       "  -166.5090151766819,\n",
       "  -155.39103498734303,\n",
       "  -153.003944198414,\n",
       "  -146.409018288316]]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_w_outline = create_prompt(outline_sents)\n",
    "res = all_the_log_probs(text_sents, question_w_outline)\n",
    "final = allLogProbs(res, text_sents, question_w_outline)\n",
    "final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
